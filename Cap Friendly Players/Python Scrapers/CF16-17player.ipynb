{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that necessary packages are installed, going to parse the needed url. This URL has stats for each player in the league for the 2016-17 season, as well as contract information only for the year of 2016-17. So I am going to scrape the cap friendly website (Players Browse tab) and get this into a dataframe that I can download and put into the MySQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_v3 = \"https://www.capfriendly.com/browse/active/2017?stats-season=2017&display=signing-team,birthday,country,weight,height,weightkg,heightcm,draft,slide-candidate,waivers-exempt,signing-status,expiry-year,performance-bonus,signing-bonus,caphit-percent,aav,length,minors-salary,base-salary,skater-individual-advanced-stats,skater-on-ice-advanced-stats,goalie-advanced-stats,arbitration-eligible,type,signing-age,signing-date,arbitration,extension&limits=gp-5-90\"\n",
    "\n",
    "req2 = requests.get(url_v3)\n",
    "soup = BeautifulSoup(req2.content)  # make a soup of html & css from the web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(url_v3, header=0, index_col = 0, na_values=[\"-\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 69)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running df.shape, we can see our dataframe has 50 rows (players) and 69 columns (attributes about that player for the 2023-24 season). There are more than 50 players but they are on different url links technically as the table on that specific url only shows 50 players. So we need to retrieve the rest of the players. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping multiple pages of the main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_about_lists = soup.find_all(\"a\", {\"class\": \"whi pagin_r\"})  # via devtools we find the element that allows to switch between pages of data\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"whi pagin_r\" data-val=\"2\" href=\"/browse/?p=2\">2</a>, <a class=\"whi pagin_r\" data-val=\"3\" href=\"/browse/?p=3\">3</a>, <a class=\"whi pagin_r\" data-val=\"18\" href=\"/browse/?p=18\">Last</a>]\n"
     ]
    }
   ],
   "source": [
    "print(info_about_lists)  # all links to other pages of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_list_num = int(info_about_lists[-1][\"data-val\"])  # take the last number of page from date-val so we now how many values were selected for us\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(last_list_num)  # check that 18th is last page number we got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use a for loop to parse all the data we have on multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start scapring page 1\n",
      "50 rows were retrieved from page number 1\n",
      "Start scapring page 2\n",
      "50 rows were retrieved from page number 2\n",
      "Start scapring page 3\n",
      "50 rows were retrieved from page number 3\n",
      "Start scapring page 4\n",
      "50 rows were retrieved from page number 4\n",
      "Start scapring page 5\n",
      "50 rows were retrieved from page number 5\n",
      "Start scapring page 6\n",
      "50 rows were retrieved from page number 6\n",
      "Start scapring page 7\n",
      "50 rows were retrieved from page number 7\n",
      "Start scapring page 8\n",
      "50 rows were retrieved from page number 8\n",
      "Start scapring page 9\n",
      "50 rows were retrieved from page number 9\n",
      "Start scapring page 10\n",
      "50 rows were retrieved from page number 10\n",
      "Start scapring page 11\n",
      "50 rows were retrieved from page number 11\n",
      "Start scapring page 12\n",
      "50 rows were retrieved from page number 12\n",
      "Start scapring page 13\n",
      "50 rows were retrieved from page number 13\n",
      "Start scapring page 14\n",
      "50 rows were retrieved from page number 14\n",
      "Start scapring page 15\n",
      "50 rows were retrieved from page number 15\n",
      "Start scapring page 16\n",
      "50 rows were retrieved from page number 16\n",
      "Start scapring page 17\n",
      "50 rows were retrieved from page number 17\n",
      "Start scapring page 18\n",
      "7 rows were retrieved from page number 18\n"
     ]
    }
   ],
   "source": [
    "req = requests.get(url_v3)\n",
    "soup = BeautifulSoup(req.content)  # make a soup of html & css from the web page\n",
    "\n",
    "info_about_lists = soup.find_all(\"a\", {\"class\": \"whi pagin_r\"})  # via devtools we find the element that allows to switch between pages of data\n",
    "last_list_num = int(info_about_lists[-1][\"data-val\"])  # take the last number of page from date-val so we now how many values were selected for us\n",
    "\n",
    "pages_dfs = []\n",
    "\n",
    "url_start = \"https://www.capfriendly.com/browse/active/2017?stats-season=2017&display=signing-team,birthday,country,weight,height,weightkg,heightcm,draft,slide-candidate,waivers-exempt,signing-status,expiry-year,performance-bonus,signing-bonus,caphit-percent,aav,length,minors-salary,base-salary,skater-individual-advanced-stats,skater-on-ice-advanced-stats,goalie-advanced-stats,arbitration-eligible,type,signing-age,signing-date,arbitration,extension&limits=gp-5-90\"\n",
    "\n",
    "for page_num in range(1, last_list_num + 1):\n",
    "\n",
    "        print(f\"Start scapring page {page_num}\")\n",
    "\n",
    "        time.sleep(1)  # let the page download the results\n",
    "\n",
    "        url = url_start + f\"&pg={page_num}\"  # we parse the needed page by adding a parameter for url\n",
    "        df = pd.read_html(url, header=0, index_col = 0, na_values=[\"-\"])[0]\n",
    "\n",
    "        df = df.reset_index()  # to have player name as a separate column\n",
    "\n",
    "        print(df.shape[0], f\"rows were retrieved from page number {page_num}\")\n",
    "\n",
    "        pages_dfs.append(df)\n",
    "\n",
    "\n",
    "result_df = pd.concat(pages_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DATE OF BIRTH</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>POS</th>\n",
       "      <th>HANDED</th>\n",
       "      <th>DRAFTED</th>\n",
       "      <th>...</th>\n",
       "      <th>EXPIRY</th>\n",
       "      <th>EXP. YEAR</th>\n",
       "      <th>CAP HIT</th>\n",
       "      <th>CAP HIT %</th>\n",
       "      <th>AAV</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>BASE SALARY</th>\n",
       "      <th>MINORS</th>\n",
       "      <th>S.BONUS</th>\n",
       "      <th>P.BONUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Jonathan Toews</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>Apr. 29, 1988</td>\n",
       "      <td>Canada</td>\n",
       "      <td>201 lbs - 91 kg</td>\n",
       "      <td>6'2\" - 188 cm</td>\n",
       "      <td>C</td>\n",
       "      <td>Left</td>\n",
       "      <td>3 - Round 1 - 2006 (CHI)</td>\n",
       "      <td>...</td>\n",
       "      <td>UFA</td>\n",
       "      <td>2023</td>\n",
       "      <td>$10,500,000</td>\n",
       "      <td>15.2%</td>\n",
       "      <td>$10,500,000</td>\n",
       "      <td>$13,800,000</td>\n",
       "      <td>$7,800,000</td>\n",
       "      <td>$13,800,000</td>\n",
       "      <td>$6,000,000</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Patrick Kane</td>\n",
       "      <td>DET</td>\n",
       "      <td>27</td>\n",
       "      <td>Nov. 19, 1988</td>\n",
       "      <td>United States</td>\n",
       "      <td>177 lbs - 80 kg</td>\n",
       "      <td>5'10\" - 178 cm</td>\n",
       "      <td>RW</td>\n",
       "      <td>Left</td>\n",
       "      <td>1 - Round 1 - 2007 (CHI)</td>\n",
       "      <td>...</td>\n",
       "      <td>UFA</td>\n",
       "      <td>2023</td>\n",
       "      <td>$10,500,000</td>\n",
       "      <td>15.2%</td>\n",
       "      <td>$10,500,000</td>\n",
       "      <td>$13,800,000</td>\n",
       "      <td>$7,800,000</td>\n",
       "      <td>$13,800,000</td>\n",
       "      <td>$6,000,000</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Anze Kopitar</td>\n",
       "      <td>LAK</td>\n",
       "      <td>28</td>\n",
       "      <td>Aug. 24, 1987</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>225 lbs - 102 kg</td>\n",
       "      <td>6'3\" - 191 cm</td>\n",
       "      <td>C</td>\n",
       "      <td>Left</td>\n",
       "      <td>11 - Round 1 - 2005 (LAK)</td>\n",
       "      <td>...</td>\n",
       "      <td>UFA</td>\n",
       "      <td>2024</td>\n",
       "      <td>$10,000,000</td>\n",
       "      <td>14.0%</td>\n",
       "      <td>$10,000,000</td>\n",
       "      <td>$14,000,000</td>\n",
       "      <td>$5,000,000</td>\n",
       "      <td>$14,000,000</td>\n",
       "      <td>$9,000,000</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Alex Ovechkin</td>\n",
       "      <td>WSH</td>\n",
       "      <td>30</td>\n",
       "      <td>Sep. 17, 1985</td>\n",
       "      <td>Russia</td>\n",
       "      <td>236 lbs - 107 kg</td>\n",
       "      <td>6'3\" - 191 cm</td>\n",
       "      <td>LW</td>\n",
       "      <td>Right</td>\n",
       "      <td>1 - Round 1 - 2004 (WSH)</td>\n",
       "      <td>...</td>\n",
       "      <td>UFA</td>\n",
       "      <td>2021</td>\n",
       "      <td>$9,538,462</td>\n",
       "      <td>19.0%</td>\n",
       "      <td>$9,538,462</td>\n",
       "      <td>$10,000,000</td>\n",
       "      <td>$10,000,000</td>\n",
       "      <td>$10,000,000</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. Evgeni Malkin</td>\n",
       "      <td>PIT</td>\n",
       "      <td>29</td>\n",
       "      <td>Jul. 31, 1986</td>\n",
       "      <td>Russia</td>\n",
       "      <td>195 lbs - 88 kg</td>\n",
       "      <td>6'3\" - 191 cm</td>\n",
       "      <td>C</td>\n",
       "      <td>Left</td>\n",
       "      <td>2 - Round 1 - 2004 (PIT)</td>\n",
       "      <td>...</td>\n",
       "      <td>UFA</td>\n",
       "      <td>2022</td>\n",
       "      <td>$9,500,000</td>\n",
       "      <td>14.8%</td>\n",
       "      <td>$9,500,000</td>\n",
       "      <td>$9,500,000</td>\n",
       "      <td>$9,500,000</td>\n",
       "      <td>$9,500,000</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PLAYER TEAM AGE  DATE OF BIRTH        COUNTRY            WEIGHT  \\\n",
       "0  1. Jonathan Toews  NaN  28  Apr. 29, 1988         Canada   201 lbs - 91 kg   \n",
       "1    2. Patrick Kane  DET  27  Nov. 19, 1988  United States   177 lbs - 80 kg   \n",
       "2    3. Anze Kopitar  LAK  28  Aug. 24, 1987       Slovenia  225 lbs - 102 kg   \n",
       "3   4. Alex Ovechkin  WSH  30  Sep. 17, 1985         Russia  236 lbs - 107 kg   \n",
       "4   5. Evgeni Malkin  PIT  29  Jul. 31, 1986         Russia   195 lbs - 88 kg   \n",
       "\n",
       "           HEIGHT POS HANDED                    DRAFTED  ...  EXPIRY  \\\n",
       "0   6'2\" - 188 cm   C   Left   3 - Round 1 - 2006 (CHI)  ...     UFA   \n",
       "1  5'10\" - 178 cm  RW   Left   1 - Round 1 - 2007 (CHI)  ...     UFA   \n",
       "2   6'3\" - 191 cm   C   Left  11 - Round 1 - 2005 (LAK)  ...     UFA   \n",
       "3   6'3\" - 191 cm  LW  Right   1 - Round 1 - 2004 (WSH)  ...     UFA   \n",
       "4   6'3\" - 191 cm   C   Left   2 - Round 1 - 2004 (PIT)  ...     UFA   \n",
       "\n",
       "  EXP. YEAR      CAP HIT  CAP HIT %          AAV       SALARY  BASE SALARY  \\\n",
       "0      2023  $10,500,000      15.2%  $10,500,000  $13,800,000   $7,800,000   \n",
       "1      2023  $10,500,000      15.2%  $10,500,000  $13,800,000   $7,800,000   \n",
       "2      2024  $10,000,000      14.0%  $10,000,000  $14,000,000   $5,000,000   \n",
       "3      2021   $9,538,462      19.0%   $9,538,462  $10,000,000  $10,000,000   \n",
       "4      2022   $9,500,000      14.8%   $9,500,000   $9,500,000   $9,500,000   \n",
       "\n",
       "        MINORS     S.BONUS  P.BONUS  \n",
       "0  $13,800,000  $6,000,000       $0  \n",
       "1  $13,800,000  $6,000,000       $0  \n",
       "2  $14,000,000  $9,000,000       $0  \n",
       "3  $10,000,000          $0       $0  \n",
       "4   $9,500,000          $0       $0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I have player statistics and cap info for the 2016-17 season. I have every player in the entire league for the 2016-17 season!!! So time to export it to a csv, and then upload it into the MySQL database I created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('Cap Friendly 2016-17 Player Data2.csv', encoding='utf-8')\n",
    "result_df.to_csv('Cap Friendly 2016-17 Player Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv file above is a weird file type **Forgot to add the .csv extension above, issue is fixed now. Just have to replace the weird \"âœ” with a Yes as when a check mark is scraped off their website, it can not get represented correctly in excel. So just replace that symbol with the text Yes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have the 2016-17 CapFriendly Player Data all downloaded, time to download the 10 prior seasons(Include that seasons stats and contract information) and 8 seasons after (will include contract information). This will be done in a separate file to ensure this notebook does not get negatively impacted. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
