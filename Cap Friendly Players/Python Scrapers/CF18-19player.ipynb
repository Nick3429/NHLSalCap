{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that necessary packages are installed, going to parse the needed url. This URL has stats for each player in the league for the 2018-19 season, as well as contract information only for the year of 2018-19. So I am going to scrape the cap friendly website (Players Browse tab) and get this into a dataframe that I can download and put into the MySQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_v3 = \"https://www.capfriendly.com/browse/active/2019?stats-season=2019&display=signing-team,birthday,country,weight,height,weightkg,heightcm,draft,slide-candidate,waivers-exempt,signing-status,expiry-year,performance-bonus,signing-bonus,caphit-percent,aav,length,minors-salary,base-salary,skater-individual-advanced-stats,skater-on-ice-advanced-stats,goalie-advanced-stats,arbitration-eligible,type,signing-age,signing-date,arbitration,extension&limits=gp-5-90\"\n",
    "\n",
    "req2 = requests.get(url_v3)\n",
    "soup = BeautifulSoup(req2.content)  # make a soup of html & css from the web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(url_v3, header=0, index_col = 0, na_values=[\"-\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 69)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running df.shape, we can see our dataframe has 50 rows (players) and 69 columns (attributes about that player for the 2023-24 season). There are more than 50 players but they are on different url links technically as the table on that specific url only shows 50 players. So we need to retrieve the rest of the players. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping multiple pages of the main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_about_lists = soup.find_all(\"a\", {\"class\": \"whi pagin_r\"})  # via devtools we find the element that allows to switch between pages of data\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"whi pagin_r\" data-val=\"2\" href=\"/browse/?p=2\">2</a>, <a class=\"whi pagin_r\" data-val=\"3\" href=\"/browse/?p=3\">3</a>, <a class=\"whi pagin_r\" data-val=\"18\" href=\"/browse/?p=18\">Last</a>]\n"
     ]
    }
   ],
   "source": [
    "print(info_about_lists)  # all links to other pages of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_list_num = int(info_about_lists[-1][\"data-val\"])  # take the last number of page from date-val so we now how many values were selected for us\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(last_list_num)  # check that 18th is last page number we got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use a for loop to parse all the data we have on multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start scapring page 1\n",
      "50 rows were retrieved from page number 1\n",
      "Start scapring page 2\n",
      "50 rows were retrieved from page number 2\n",
      "Start scapring page 3\n",
      "50 rows were retrieved from page number 3\n",
      "Start scapring page 4\n",
      "50 rows were retrieved from page number 4\n",
      "Start scapring page 5\n",
      "50 rows were retrieved from page number 5\n",
      "Start scapring page 6\n",
      "50 rows were retrieved from page number 6\n",
      "Start scapring page 7\n",
      "50 rows were retrieved from page number 7\n",
      "Start scapring page 8\n",
      "50 rows were retrieved from page number 8\n",
      "Start scapring page 9\n",
      "50 rows were retrieved from page number 9\n",
      "Start scapring page 10\n",
      "50 rows were retrieved from page number 10\n",
      "Start scapring page 11\n",
      "50 rows were retrieved from page number 11\n",
      "Start scapring page 12\n",
      "50 rows were retrieved from page number 12\n",
      "Start scapring page 13\n",
      "50 rows were retrieved from page number 13\n",
      "Start scapring page 14\n",
      "50 rows were retrieved from page number 14\n",
      "Start scapring page 15\n",
      "50 rows were retrieved from page number 15\n",
      "Start scapring page 16\n",
      "50 rows were retrieved from page number 16\n",
      "Start scapring page 17\n",
      "50 rows were retrieved from page number 17\n",
      "Start scapring page 18\n",
      "48 rows were retrieved from page number 18\n"
     ]
    }
   ],
   "source": [
    "req = requests.get(url_v3)\n",
    "soup = BeautifulSoup(req.content)  # make a soup of html & css from the web page\n",
    "\n",
    "info_about_lists = soup.find_all(\"a\", {\"class\": \"whi pagin_r\"})  # via devtools we find the element that allows to switch between pages of data\n",
    "last_list_num = int(info_about_lists[-1][\"data-val\"])  # take the last number of page from date-val so we now how many values were selected for us\n",
    "\n",
    "pages_dfs = []\n",
    "\n",
    "url_start = \"https://www.capfriendly.com/browse/active/2019?stats-season=2019&display=signing-team,birthday,country,weight,height,weightkg,heightcm,draft,slide-candidate,waivers-exempt,signing-status,expiry-year,performance-bonus,signing-bonus,caphit-percent,aav,length,minors-salary,base-salary,skater-individual-advanced-stats,skater-on-ice-advanced-stats,goalie-advanced-stats,arbitration-eligible,type,signing-age,signing-date,arbitration,extension&limits=gp-5-90\"\n",
    "\n",
    "for page_num in range(1, last_list_num + 1):\n",
    "\n",
    "        print(f\"Start scapring page {page_num}\")\n",
    "\n",
    "        time.sleep(1)  # let the page download the results\n",
    "\n",
    "        url = url_start + f\"&pg={page_num}\"  # we parse the needed page by adding a parameter for url\n",
    "        df = pd.read_html(url, header=0, index_col = 0, na_values=[\"-\"])[0]\n",
    "\n",
    "        df = df.reset_index()  # to have player name as a separate column\n",
    "\n",
    "        print(df.shape[0], f\"rows were retrieved from page number {page_num}\")\n",
    "\n",
    "        pages_dfs.append(df)\n",
    "\n",
    "\n",
    "result_df = pd.concat(pages_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DATE OF BIRTH</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>POS</th>\n",
       "      <th>HANDED</th>\n",
       "      <th>DRAFTED</th>\n",
       "      <th>...</th>\n",
       "      <th>EXPIRY</th>\n",
       "      <th>EXP. YEAR</th>\n",
       "      <th>CAP HIT</th>\n",
       "      <th>CAP HIT %</th>\n",
       "      <th>AAV</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>BASE SALARY</th>\n",
       "      <th>MINORS</th>\n",
       "      <th>S.BONUS</th>\n",
       "      <th>P.BONUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Connor McDavid</td>\n",
       "      <td>EDM</td>\n",
       "      <td>21</td>\n",
       "      <td>Jan. 13, 1997</td>\n",
       "      <td>Canada</td>\n",
       "      <td>193 lbs - 88 kg</td>\n",
       "      <td>6'1\" - 185 cm</td>\n",
       "      <td>C</td>\n",
       "      <td>Left</td>\n",
       "      <td>1 - Round 1 - 2015 (EDM)</td>\n",
       "      <td>...</td>\n",
       "      <td>UFA</td>\n",
       "      <td>2026</td>\n",
       "      <td>$12,500,000</td>\n",
       "      <td>16.7%</td>\n",
       "      <td>$12,500,000</td>\n",
       "      <td>$15,000,000</td>\n",
       "      <td>$2,000,000</td>\n",
       "      <td>$15,000,000</td>\n",
       "      <td>$13,000,000</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. John Tavares</td>\n",
       "      <td>TOR</td>\n",
       "      <td>27</td>\n",
       "      <td>Sep. 20, 1990</td>\n",
       "      <td>Canada</td>\n",
       "      <td>215 lbs - 98 kg</td>\n",
       "      <td>6'1\" - 185 cm</td>\n",
       "      <td>C, LW</td>\n",
       "      <td>Left</td>\n",
       "      <td>1 - Round 1 - 2009 (NYI)</td>\n",
       "      <td>...</td>\n",
       "      <td>UFA</td>\n",
       "      <td>2025</td>\n",
       "      <td>$11,000,000</td>\n",
       "      <td>13.8%</td>\n",
       "      <td>$11,000,000</td>\n",
       "      <td>$15,900,000</td>\n",
       "      <td>$650,000</td>\n",
       "      <td>$15,900,000</td>\n",
       "      <td>$15,250,000</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Carey Price</td>\n",
       "      <td>MTL</td>\n",
       "      <td>30</td>\n",
       "      <td>Aug. 16, 1987</td>\n",
       "      <td>Canada</td>\n",
       "      <td>217 lbs - 98 kg</td>\n",
       "      <td>6'3\" - 191 cm</td>\n",
       "      <td>G</td>\n",
       "      <td>Left</td>\n",
       "      <td>5 - Round 1 - 2005 (MTL)</td>\n",
       "      <td>...</td>\n",
       "      <td>UFA</td>\n",
       "      <td>2026</td>\n",
       "      <td>$10,500,000</td>\n",
       "      <td>14.0%</td>\n",
       "      <td>$10,500,000</td>\n",
       "      <td>$15,000,000</td>\n",
       "      <td>$2,000,000</td>\n",
       "      <td>$15,000,000</td>\n",
       "      <td>$13,000,000</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Jonathan Toews</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>Apr. 29, 1988</td>\n",
       "      <td>Canada</td>\n",
       "      <td>201 lbs - 91 kg</td>\n",
       "      <td>6'2\" - 188 cm</td>\n",
       "      <td>C</td>\n",
       "      <td>Left</td>\n",
       "      <td>3 - Round 1 - 2006 (CHI)</td>\n",
       "      <td>...</td>\n",
       "      <td>UFA</td>\n",
       "      <td>2023</td>\n",
       "      <td>$10,500,000</td>\n",
       "      <td>15.2%</td>\n",
       "      <td>$10,500,000</td>\n",
       "      <td>$12,000,000</td>\n",
       "      <td>$6,000,000</td>\n",
       "      <td>$12,000,000</td>\n",
       "      <td>$6,000,000</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. Patrick Kane</td>\n",
       "      <td>DET</td>\n",
       "      <td>29</td>\n",
       "      <td>Nov. 19, 1988</td>\n",
       "      <td>United States</td>\n",
       "      <td>177 lbs - 80 kg</td>\n",
       "      <td>5'10\" - 178 cm</td>\n",
       "      <td>RW</td>\n",
       "      <td>Left</td>\n",
       "      <td>1 - Round 1 - 2007 (CHI)</td>\n",
       "      <td>...</td>\n",
       "      <td>UFA</td>\n",
       "      <td>2023</td>\n",
       "      <td>$10,500,000</td>\n",
       "      <td>15.2%</td>\n",
       "      <td>$10,500,000</td>\n",
       "      <td>$12,000,000</td>\n",
       "      <td>$6,000,000</td>\n",
       "      <td>$12,000,000</td>\n",
       "      <td>$6,000,000</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PLAYER TEAM AGE  DATE OF BIRTH        COUNTRY           WEIGHT  \\\n",
       "0  1. Connor McDavid  EDM  21  Jan. 13, 1997         Canada  193 lbs - 88 kg   \n",
       "1    2. John Tavares  TOR  27  Sep. 20, 1990         Canada  215 lbs - 98 kg   \n",
       "2     3. Carey Price  MTL  30  Aug. 16, 1987         Canada  217 lbs - 98 kg   \n",
       "3  4. Jonathan Toews  NaN  30  Apr. 29, 1988         Canada  201 lbs - 91 kg   \n",
       "4    5. Patrick Kane  DET  29  Nov. 19, 1988  United States  177 lbs - 80 kg   \n",
       "\n",
       "           HEIGHT    POS HANDED                   DRAFTED  ...  EXPIRY  \\\n",
       "0   6'1\" - 185 cm      C   Left  1 - Round 1 - 2015 (EDM)  ...     UFA   \n",
       "1   6'1\" - 185 cm  C, LW   Left  1 - Round 1 - 2009 (NYI)  ...     UFA   \n",
       "2   6'3\" - 191 cm      G   Left  5 - Round 1 - 2005 (MTL)  ...     UFA   \n",
       "3   6'2\" - 188 cm      C   Left  3 - Round 1 - 2006 (CHI)  ...     UFA   \n",
       "4  5'10\" - 178 cm     RW   Left  1 - Round 1 - 2007 (CHI)  ...     UFA   \n",
       "\n",
       "  EXP. YEAR      CAP HIT  CAP HIT %          AAV       SALARY  BASE SALARY  \\\n",
       "0      2026  $12,500,000      16.7%  $12,500,000  $15,000,000   $2,000,000   \n",
       "1      2025  $11,000,000      13.8%  $11,000,000  $15,900,000     $650,000   \n",
       "2      2026  $10,500,000      14.0%  $10,500,000  $15,000,000   $2,000,000   \n",
       "3      2023  $10,500,000      15.2%  $10,500,000  $12,000,000   $6,000,000   \n",
       "4      2023  $10,500,000      15.2%  $10,500,000  $12,000,000   $6,000,000   \n",
       "\n",
       "        MINORS      S.BONUS  P.BONUS  \n",
       "0  $15,000,000  $13,000,000       $0  \n",
       "1  $15,900,000  $15,250,000       $0  \n",
       "2  $15,000,000  $13,000,000       $0  \n",
       "3  $12,000,000   $6,000,000       $0  \n",
       "4  $12,000,000   $6,000,000       $0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I have player statistics and cap info for the 2018-19 season. I have every player in the entire league for the 2018-19 season!!! So time to export it to a csv, and then upload it into the MySQL database I created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('Cap Friendly 2018-19 Player Data2.csv', encoding='utf-8')\n",
    "result_df.to_csv('Cap Friendly 2018-19 Player Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv file above is a weird file type **Forgot to add the .csv extension above, issue is fixed now. Just have to replace the weird \"âœ” with a Yes as when a check mark is scraped off their website, it can not get represented correctly in excel. So just replace that symbol with the text Yes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have the 2018-19 CapFriendly Player Data all downloaded, time to download the 10 prior seasons(Include that seasons stats and contract information) and 8 seasons after (will include contract information). This will be done in a separate file to ensure this notebook does not get negatively impacted. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
